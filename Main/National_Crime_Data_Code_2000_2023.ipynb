{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from config import api_key, census_api_key\n",
    "from census import Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing homicide: API call failed with status 500\n",
      "Error processing rape: API call failed with status 500\n",
      "Error processing robbery: API call failed with status 500\n",
      "Error processing aggravated-assault: API call failed with status 500\n",
      "Error processing arson: API call failed with status 500\n",
      "Error processing burglary: API call failed with status 500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 106\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# Pause for a short time to avoid overloading the API (to stay within rate limits)\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Concatenate the aggregated data into a single DataFrame\u001b[39;00m\n\u001b[0;32m    109\u001b[0m aggregated_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(aggregated_data, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the date range for the data query\n",
    "begin_date = \"01-2000\"\n",
    "end_date = \"12-2023\"\n",
    "time_frame = f'?from={begin_date}&to={end_date}'\n",
    "\n",
    "# List of crime types for which data will be fetched\n",
    "crime = [\"homicide\", \"rape\", \"robbery\", \"aggravated-assault\", \"arson\", \"burglary\", \"larceny\", \"motor-vehicle-theft\"]\n",
    "\n",
    "# Function to fetch national crime data from the API\n",
    "def fetch_crime_data(crime, time_frame, api_key):\n",
    "    # Construct the base URL to call the API with the crime type and time frame\n",
    "    base_url = f'https://api.usa.gov/crime/fbi/cde/summarized/national/{crime}{time_frame}{api_key}'\n",
    "    response = requests.get(base_url)\n",
    "    \n",
    "    # Check if the API call was successful (status code 200)\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(f\"API call failed with status {response.status_code}\")\n",
    "    \n",
    "    # Return the JSON response if successful\n",
    "    return response.json()\n",
    "\n",
    "# Function to process the fetched national crime data into a DataFrame\n",
    "def process_crime_data(crime_data):\n",
    "    # Convert the raw crime data into a Pandas DataFrame\n",
    "    df = pd.DataFrame(crime_data)\n",
    "    \n",
    "    # Define the columns to extract from the crime data JSON\n",
    "    data_columns = {\n",
    "        \"Total Crimes\": \"offenses.actuals.United States\",\n",
    "        \"Clearances\": \"offenses.actuals.United States Clearances\",\n",
    "        \"Crime(Per 100k)\": \"offenses.rates.United States\",\n",
    "        \"Prosecutions(Per 100k)\": \"offenses.rates.United States Clearances\",\n",
    "        \"Total Pop\": \"populations.population.United States\",\n",
    "        \"Partic Pop\": \"populations.participated_population.United States\",\n",
    "        \"Pop Coverage\": \"tooltips.Percent of Population Coverage.United States\"\n",
    "    }\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    # Iterate over the defined columns and extract the relevant data\n",
    "    for col_name, key_path in data_columns.items():\n",
    "        # Split the key path into individual keys to navigate through the nested JSON\n",
    "        keys = key_path.split(\".\")\n",
    "        data = crime_data\n",
    "        \n",
    "        # Navigate through the nested JSON structure using the keys\n",
    "        for key in keys:\n",
    "            data = data.get(key, {})\n",
    "        \n",
    "        # Extract the values and store them in the result dictionary\n",
    "        result[col_name] = list(data.values())\n",
    "        result[\"Crime Type\"] = c\n",
    "    \n",
    "    # Return the processed data as a DataFrame\n",
    "    return pd.DataFrame(result, index=list(data.keys()))\n",
    "\n",
    "# Initialize an empty list to store the aggregated data\n",
    "aggregated_data = []\n",
    "\n",
    "# Iterate over each crime type to fetch, process, and aggregate the data\n",
    "for c in crime:\n",
    "    try:\n",
    "        # Fetch crime data for the current crime type\n",
    "        crime_data = fetch_crime_data(c, time_frame, api_key)\n",
    "        \n",
    "        # Process the crime data into a DataFrame\n",
    "        df_crime_data = process_crime_data(crime_data)\n",
    "        \n",
    "        # Calculate the \"Prosecuted %\" as the ratio of clearances to total crimes, rounded to two decimal places\n",
    "        df_crime_data[\"Prosecuted %\"] = (df_crime_data[\"Clearances\"] / df_crime_data[\"Total Crimes\"]).round(2)\n",
    "        \n",
    "        # Convert the index (months) to DateTime format for consistency\n",
    "        df_crime_data.index = pd.to_datetime(df_crime_data.index, format='%m-%Y', errors='coerce')\n",
    "        \n",
    "        # Reset the index and rename the column to \"Month\"\n",
    "        df_crime_data = df_crime_data.reset_index().rename(columns={\"index\": \"Month\"})\n",
    "        \n",
    "        # Sort the data by \"Month\" for chronological order\n",
    "        df_sorted = df_crime_data.sort_values(by=[\"Month\"])\n",
    "        \n",
    "        # Aggregate the data by year\n",
    "        yearly_data = df_sorted.groupby(df_sorted[\"Month\"].dt.year).agg({\n",
    "            \"Total Crimes\": \"sum\",\n",
    "            \"Clearances\": \"sum\",\n",
    "            \"Crime(Per 100k)\": \"mean\",\n",
    "            \"Prosecutions(Per 100k)\": \"mean\",\n",
    "            \"Prosecuted %\": \"mean\",\n",
    "            \"Total Pop\": \"last\",\n",
    "            \"Partic Pop\": \"last\",\n",
    "            \"Pop Coverage\": \"last\"\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Add a column for the crime type\n",
    "        yearly_data[\"Crime Type\"] = c\n",
    "        \n",
    "        # Append the aggregated data to the list\n",
    "        aggregated_data.append(yearly_data)\n",
    "        \n",
    "        # Log the successful processing and aggregation of data\n",
    "        print(f\"Processed Data for {c}\")\n",
    "    except Exception as e:\n",
    "        # Log any errors encountered during processing\n",
    "        print(f\"Error processing {c}: {e}\")\n",
    "    \n",
    "    # Pause for a short time to avoid overloading the API (to stay within rate limits)\n",
    "    time.sleep(2)\n",
    "\n",
    "# Concatenate the aggregated data into a single DataFrame\n",
    "aggregated_df = pd.concat(aggregated_data, ignore_index=True)\n",
    "\n",
    "# Separate violent and property crimes into different columns\n",
    "violent_crimes = [\"homicide\", \"rape\", \"robbery\", \"aggravated-assault\"]\n",
    "property_crimes = [\"arson\", \"burglary\", \"larceny\", \"motor-vehicle-theft\"]\n",
    "\n",
    "aggregated_df[\"Violent Crimes\"] = aggregated_df.apply(lambda row: row[\"Total Crimes\"] if row[\"Crime Type\"] in violent_crimes else 0, axis=1)\n",
    "aggregated_df[\"Property Crimes\"] = aggregated_df.apply(lambda row: row[\"Total Crimes\"] if row[\"Crime Type\"] in property_crimes else 0, axis=1)\n",
    "\n",
    "# Group by year and sum the violent and property crimes\n",
    "final_df = aggregated_df.groupby(\"Month\").agg({\n",
    "    \"Violent Crimes\": \"sum\",\n",
    "    \"Property Crimes\": \"sum\",\n",
    "    \"Total Pop\": \"last\",\n",
    "    \"Partic Pop\": \"last\",\n",
    "    \"Pop Coverage\": \"last\"\n",
    "}).reset_index()\n",
    "\n",
    "# Rename the \"Month\" column to \"Year\"\n",
    "final_df = final_df.rename(columns={\"Month\": \"Year\"})\n",
    "\n",
    "final_df['Violent Crime Rate'] = round((final_df['Violent Crimes'] / final_df['Total Pop']) * 100000,2)\n",
    "final_df['Property Crime Rate'] = round((final_df['Property Crimes'] / final_df['Total Pop']) * 100000,2)\n",
    "final_df['Total Crime Rate'] = round(((final_df['Violent Crimes'] + final_df['Property Crimes']) / final_df['Total Pop']) * 100000,2)\n",
    "final_df = final_df[[\"Year\", \"Violent Crimes\", \"Violent Crime Rate\", \"Property Crimes\", \"Property Crime Rate\", \"Total Pop\", \n",
    "                     \"Partic Pop\", \"Pop Coverage\", \"Total Crime Rate\"]]\n",
    "\n",
    "# Run through Data for Poverty Count from Census\n",
    "for index, row in final_df.iterrows():\n",
    "    try:\n",
    "        year = int(row['Year'])\n",
    "        c = Census(\n",
    "            census_api_key,\n",
    "            year=year\n",
    "        )\n",
    "        census_data = c.acs5.get(\n",
    "            (\n",
    "                \"B17001_002E\"\n",
    "            ),\n",
    "            {'for': 'us'}\n",
    "        )\n",
    "\n",
    "        # Extract the poverty count\n",
    "        poverty_count = census_data[0]['B17001_002E']\n",
    "        final_df.at[index, 'Poverty Count'] = int(poverty_count)\n",
    "\n",
    "        print(f\"Grabbed poverty count for {year}\")\n",
    "\n",
    "    except Exception:\n",
    "        print(f\"Census does not contain poverty data for {year}.\")\n",
    "\n",
    "# Calculate poverty rate\n",
    "final_df[\"Poverty Rate\"] = round(final_df['Poverty Count'] / final_df['Total Pop'] * 100,2)\n",
    "final_df['Poverty Count'] = final_df['Poverty Count'].fillna(0).astype(int)\n",
    "final_df[\"Total Crimes\"] = final_df['Violent Crimes'] + final_df[\"Property Crimes\"]\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "final_df.to_csv(\"../Resources/National/National_Crime_Poverty.csv\", index=False)\n",
    "\n",
    "print(\"Final aggregated data saved to '../Resources/National/National_Crime_Poverty.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
