{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from config import api_key, census_api_key\n",
    "from pprint import pprint\n",
    "from census import Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for Alaska (AK)\n",
      "Processed data for Alabama (AL)\n",
      "Processed data for Arkansas (AR)\n",
      "Processed data for Arizona (AZ)\n",
      "Processed data for California (CA)\n",
      "Processed data for Colorado (CO)\n",
      "Processed data for Connecticut (CT)\n",
      "Processed data for District of Columbia (DC)\n",
      "Processed data for Delaware (DE)\n",
      "Processed data for Florida (FL)\n",
      "Processed data for Georgia (GA)\n",
      "Processed data for Hawaii (HI)\n",
      "Processed data for Iowa (IA)\n",
      "Processed data for Idaho (ID)\n",
      "Processed data for Illinois (IL)\n",
      "Processed data for Indiana (IN)\n",
      "Processed data for Kansas (KS)\n",
      "Processed data for Kentucky (KY)\n",
      "Processed data for Louisiana (LA)\n",
      "Processed data for Massachusetts (MA)\n",
      "Processed data for Maryland (MD)\n",
      "Processed data for Maine (ME)\n",
      "Processed data for Michigan (MI)\n",
      "Processed data for Minnesota (MN)\n",
      "Processed data for Missouri (MO)\n",
      "Processed data for Mississippi (MS)\n",
      "Processed data for Montana (MT)\n",
      "Processed data for North Carolina (NC)\n",
      "Processed data for North Dakota (ND)\n",
      "Processed data for Nebraska (NE)\n",
      "Processed data for New Hampshire (NH)\n",
      "Processed data for New Jersey (NJ)\n",
      "Processed data for New Mexico (NM)\n",
      "Processed data for Nevada (NV)\n",
      "Processed data for New York (NY)\n",
      "Processed data for Ohio (OH)\n",
      "Processed data for Oklahoma (OK)\n",
      "Processed data for Oregon (OR)\n",
      "Processed data for Pennsylvania (PA)\n",
      "Processed data for Rhode Island (RI)\n",
      "Processed data for South Carolina (SC)\n",
      "Processed data for South Dakota (SD)\n",
      "Processed data for Tennessee (TN)\n",
      "Processed data for Texas (TX)\n",
      "Processed data for Utah (UT)\n",
      "Processed data for Virginia (VA)\n",
      "Processed data for Vermont (VT)\n",
      "Processed data for Washington (WA)\n",
      "Processed data for Wisconsin (WI)\n",
      "Processed data for West Virginia (WV)\n",
      "Processed data for Wyoming (WY)\n",
      "All filtered agency data saved to ../Resources/Agency/Agency_Data/filtered_city_agencies.csv\n"
     ]
    }
   ],
   "source": [
    "# List of states with their abbreviations\n",
    "states = {\n",
    "    \"AK\": \"Alaska\", \"AL\": \"Alabama\", \"AR\": \"Arkansas\", \"AZ\": \"Arizona\",\n",
    "    \"CA\": \"California\", \"CO\": \"Colorado\", \"CT\": \"Connecticut\", \"DC\": \"District of Columbia\",\n",
    "    \"DE\": \"Delaware\", \"FL\": \"Florida\", \"GA\": \"Georgia\", \"HI\": \"Hawaii\",\n",
    "    \"IA\": \"Iowa\", \"ID\": \"Idaho\", \"IL\": \"Illinois\", \"IN\": \"Indiana\",\n",
    "    \"KS\": \"Kansas\", \"KY\": \"Kentucky\", \"LA\": \"Louisiana\", \"MA\": \"Massachusetts\",\n",
    "    \"MD\": \"Maryland\", \"ME\": \"Maine\", \"MI\": \"Michigan\", \"MN\": \"Minnesota\",\n",
    "    \"MO\": \"Missouri\", \"MS\": \"Mississippi\", \"MT\": \"Montana\", \"NC\": \"North Carolina\",\n",
    "    \"ND\": \"North Dakota\", \"NE\": \"Nebraska\", \"NH\": \"New Hampshire\", \"NJ\": \"New Jersey\",\n",
    "    \"NM\": \"New Mexico\", \"NV\": \"Nevada\", \"NY\": \"New York\", \"OH\": \"Ohio\",\n",
    "    \"OK\": \"Oklahoma\", \"OR\": \"Oregon\", \"PA\": \"Pennsylvania\", \"RI\": \"Rhode Island\",\n",
    "    \"SC\": \"South Carolina\", \"SD\": \"South Dakota\", \"TN\": \"Tennessee\", \"TX\": \"Texas\",\n",
    "    \"UT\": \"Utah\", \"VA\": \"Virginia\", \"VT\": \"Vermont\", \"WA\": \"Washington\",\n",
    "    \"WI\": \"Wisconsin\", \"WV\": \"West Virginia\", \"WY\": \"Wyoming\"\n",
    "}\n",
    "\n",
    "# Function to fetch agency data from the API\n",
    "def fetch_agency_data(state_abbr):\n",
    "    base_url = f'https://api.usa.gov/crime/fbi/cde/agency/byStateAbbr/{state_abbr}'\n",
    "    response = requests.get(base_url, api_key)\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(f\"API call failed for {state_abbr} with status {response.status_code}\")\n",
    "    return response.json()\n",
    "\n",
    "# List to hold filtered data from all states\n",
    "all_filtered_data = []\n",
    "\n",
    "# Iterate over each state and process the data\n",
    "for state_abbr, state_name in states.items():\n",
    "    try:\n",
    "        # Fetch data for the current state\n",
    "        response = fetch_agency_data(state_abbr)\n",
    "        \n",
    "        # Iterate through all counties in the response data\n",
    "        for county, agencies in response.items():\n",
    "            for agency in agencies:\n",
    "                # Filter agencies with `agency_type_name` == \"City\" and valid coordinates\n",
    "                if (\n",
    "                    agency.get('agency_type_name') == 'City' and\n",
    "                    agency.get('latitude') is not None and\n",
    "                    agency.get('longitude') is not None\n",
    "                ):\n",
    "                    # Append filtered data to the list\n",
    "                    all_filtered_data.append({\n",
    "                        'State': state_abbr,\n",
    "                        'Agency Name': agency.get('agency_name'),\n",
    "                        'Latitude': agency.get('latitude'),\n",
    "                        'Longitude': agency.get('longitude'),\n",
    "                        'ORI': agency.get('ori'),\n",
    "                    })\n",
    "        print(f\"Processed data for {state_name} ({state_abbr})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {state_name} ({state_abbr}): {e}\")\n",
    "    \n",
    "    # Pause to avoid overloading the API\n",
    "    time.sleep(1)\n",
    "\n",
    "# Convert the collected data into a single Pandas DataFrame\n",
    "df_all_agencies = pd.DataFrame(all_filtered_data)\n",
    "\n",
    "# Add a new \"City\" column by removing \"Police Department\" from the \"Agency Name\"\n",
    "df_all_agencies[\"City\"] = (\n",
    "    df_all_agencies[\"Agency Name\"]\n",
    "    .str.replace(r\"Police Department\", \"\", regex=True)  # Remove \"Police Department\"\n",
    "    .str.strip()  # Remove leading/trailing spaces\n",
    ")\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_path = \"../Resources/Agency/Agency_Data/filtered_city_agencies.csv\"\n",
    "df_all_agencies.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"All filtered agency data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Agency Name</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>ORI</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>Nome Police Department</td>\n",
       "      <td>64.783686</td>\n",
       "      <td>-164.188912</td>\n",
       "      <td>AK0010600</td>\n",
       "      <td>Nome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>Sitka Police Department</td>\n",
       "      <td>57.052124</td>\n",
       "      <td>-135.334180</td>\n",
       "      <td>AK0010900</td>\n",
       "      <td>Sitka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>Bethel Police Department</td>\n",
       "      <td>60.928916</td>\n",
       "      <td>-160.153350</td>\n",
       "      <td>AK0011300</td>\n",
       "      <td>Bethel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>Haines Police Department</td>\n",
       "      <td>59.098771</td>\n",
       "      <td>-135.576936</td>\n",
       "      <td>AK0012100</td>\n",
       "      <td>Haines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>Juneau Police Department</td>\n",
       "      <td>58.356556</td>\n",
       "      <td>-134.507310</td>\n",
       "      <td>AK0010300</td>\n",
       "      <td>Juneau</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State               Agency Name   Latitude   Longitude        ORI    City\n",
       "0    AK    Nome Police Department  64.783686 -164.188912  AK0010600    Nome\n",
       "1    AK   Sitka Police Department  57.052124 -135.334180  AK0010900   Sitka\n",
       "2    AK  Bethel Police Department  60.928916 -160.153350  AK0011300  Bethel\n",
       "3    AK  Haines Police Department  59.098771 -135.576936  AK0012100  Haines\n",
       "4    AK  Juneau Police Department  58.356556 -134.507310  AK0010300  Juneau"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_agencies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Population Data for Nome, AK and appended it to population_list.\n",
      "Found Population Data for Sitka, AK and appended it to population_list.\n",
      "Found Population Data for Bethel, AK and appended it to population_list.\n",
      "Found Population Data for Haines, AK and appended it to population_list.\n",
      "Found Population Data for Juneau, AK and appended it to population_list.\n",
      "Found Population Data for Skagway, AK and appended it to population_list.\n",
      "Found Population Data for Wrangell, AK and appended it to population_list.\n",
      "Found Population Data for Anchorage, AK and appended it to population_list.\n",
      "Found Population Data for Dillingham, AK and appended it to population_list.\n",
      "Found Population Data for Petersburg, AK and appended it to population_list.\n",
      "Found Population Data for Bristol Bay Borough, AK and appended it to population_list.\n",
      "Found Population Data for North Slope Borough, AK and appended it to population_list.\n",
      "Found Population Data for Hoonah, AK and appended it to population_list.\n",
      "Found Population Data for Kodiak, AK and appended it to population_list.\n",
      "Found Population Data for Sand Point, AK and appended it to population_list.\n",
      "Found Population Data for Unalaska, AK and appended it to population_list.\n",
      "Found Population Data for St. Paul, AK and appended it to population_list.\n",
      "Found Population Data for Cordova, AK and appended it to population_list.\n",
      "Found Population Data for Valdez, AK and appended it to population_list.\n",
      "Found Population Data for Whittier, AK and appended it to population_list.\n",
      "Found Population Data for Seldovia, AK and appended it to population_list.\n",
      "Found Population Data for Seward, AK and appended it to population_list.\n",
      "Found Population Data for Soldotna, AK and appended it to population_list.\n",
      "Found Population Data for Homer, AK and appended it to population_list.\n",
      "Found Population Data for Kenai, AK and appended it to population_list.\n",
      "Found Population Data for Kotzebue, AK and appended it to population_list.\n",
      "Found Population Data for Ketchikan, AK and appended it to population_list.\n",
      "Found Population Data for Wasilla, AK and appended it to population_list.\n",
      "Found Population Data for Palmer, AK and appended it to population_list.\n",
      "Found Population Data for North Pole, AK and appended it to population_list.\n",
      "Found Population Data for Fairbanks, AK and appended it to population_list.\n",
      "Found Population Data for Craig, AK and appended it to population_list.\n",
      "Found Population Data for Klawock, AK and appended it to population_list.\n",
      "Found Population Data for Opelika, AL and appended it to population_list.\n",
      "Found Population Data for Auburn, AL and appended it to population_list.\n",
      "Found Population Data for Centreville, AL and appended it to population_list.\n",
      "Found Population Data for West Blocton, AL and appended it to population_list.\n",
      "Found Population Data for Brent, AL and appended it to population_list.\n",
      "Found Population Data for Lineville, AL and appended it to population_list.\n",
      "Found Population Data for Ashland, AL and appended it to population_list.\n",
      "Found Population Data for Clayhatchee, AL and appended it to population_list.\n",
      "Found Population Data for Ozark, AL and appended it to population_list.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 61\u001b[0m\n\u001b[0;32m     57\u001b[0m state_abbr \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# Fetch the population for the current city\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m     population \u001b[38;5;241m=\u001b[39m get_population_for_city(city, state_abbr)\n\u001b[0;32m     62\u001b[0m     population_list\u001b[38;5;241m.\u001b[39mappend(population)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound Population Data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate_abbr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and appended it to population_list.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m, in \u001b[0;36mget_population_for_city\u001b[1;34m(city, state_abbr)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid state abbreviation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate_abbr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Get population data for the specific city\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m census_data \u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m.\u001b[39macs5\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m     24\u001b[0m     (\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNAME\u001b[39m\u001b[38;5;124m\"\u001b[39m,          \u001b[38;5;66;03m# City name\u001b[39;00m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB01003_001E\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;66;03m# Total population\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     ),\n\u001b[0;32m     28\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplace:*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate_fips\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Convert to DataFrame\u001b[39;00m\n\u001b[0;32m     32\u001b[0m census_pd \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(census_data)\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\site-packages\\census\\core.py:325\u001b[0m, in \u001b[0;36mACSClient.get\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_endpoints(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_year))\n\u001b[1;32m--> 325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(ACSClient, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\site-packages\\census\\core.py:159\u001b[0m, in \u001b[0;36mClient.get\u001b[1;34m(self, fields, geo, year, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m sort_by_geoid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(fields) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m49\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m year \u001b[38;5;129;01mor\u001b[39;00m year \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2009\u001b[39m)\n\u001b[0;32m    157\u001b[0m all_results \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery(forty_nine_fields, geo, year, sort_by_geoid\u001b[38;5;241m=\u001b[39msort_by_geoid, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m forty_nine_fields \u001b[38;5;129;01min\u001b[39;00m chunks(fields, \u001b[38;5;241m49\u001b[39m))\n\u001b[1;32m--> 159\u001b[0m merged_results \u001b[38;5;241m=\u001b[39m [merge(result) \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_results)]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merged_results\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\site-packages\\census\\core.py:157\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03mThe API only accepts up to 50 fields on each query.\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;124;03mChunk requests, and use the unique GEO_ID to match up the chunks\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03min case the responses are in different orders.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03mGEO_ID is not reliably present in pre-2010 requests.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    156\u001b[0m sort_by_geoid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(fields) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m49\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m year \u001b[38;5;129;01mor\u001b[39;00m year \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2009\u001b[39m)\n\u001b[1;32m--> 157\u001b[0m all_results \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery(forty_nine_fields, geo, year, sort_by_geoid\u001b[38;5;241m=\u001b[39msort_by_geoid, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m forty_nine_fields \u001b[38;5;129;01min\u001b[39;00m chunks(fields, \u001b[38;5;241m49\u001b[39m))\n\u001b[0;32m    159\u001b[0m merged_results \u001b[38;5;241m=\u001b[39m [merge(result) \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_results)]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merged_results\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\site-packages\\census\\core.py:60\u001b[0m, in \u001b[0;36mretry_on_transient_error.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m         result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m CensusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was an error while running your query.  We\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mve logged the error and we\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mll correct it ASAP.  Sorry for the inconvenience.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\site-packages\\census\\core.py:186\u001b[0m, in \u001b[0;36mClient.query\u001b[1;34m(self, fields, geo, year, sort_by_geoid, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m geo:\n\u001b[0;32m    184\u001b[0m     params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m geo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 186\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mget(url, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\site-packages\\requests\\sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \n\u001b[0;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mf:\\Anaconda\\Lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c = Census(census_api_key, year=2021)\n",
    "\n",
    "# Dictionary mapping state abbreviations to FIPS codes\n",
    "state_abbr_to_fips = {\n",
    "    'AL': '01', 'AK': '02', 'AZ': '04', 'AR': '05', 'CA': '06', 'CO': '08', 'CT': '09',\n",
    "    'DE': '10', 'DC': '11', 'FL': '12', 'GA': '13', 'HI': '15', 'ID': '16', 'IL': '17',\n",
    "    'IN': '18', 'IA': '19', 'KS': '20', 'KY': '21', 'LA': '22', 'ME': '23', 'MD': '24',\n",
    "    'MA': '25', 'MI': '26', 'MN': '27', 'MS': '28', 'MO': '29', 'MT': '30', 'NE': '31',\n",
    "    'NV': '32', 'NH': '33', 'NJ': '34', 'NM': '35', 'NY': '36', 'NC': '37', 'ND': '38',\n",
    "    'OH': '39', 'OK': '40', 'OR': '41', 'PA': '42', 'RI': '44', 'SC': '45', 'SD': '46',\n",
    "    'TN': '47', 'TX': '48', 'UT': '49', 'VT': '50', 'VA': '51', 'WA': '53', 'WV': '54',\n",
    "    'WI': '55', 'WY': '56'\n",
    "}\n",
    "\n",
    "# Function to get population data for a specific city and state\n",
    "def get_population_for_city(city, state_abbr):\n",
    "    # Convert state abbreviation to FIPS code\n",
    "    state_fips = state_abbr_to_fips.get(state_abbr)\n",
    "    if not state_fips:\n",
    "        raise ValueError(f\"Invalid state abbreviation: {state_abbr}\")\n",
    "    \n",
    "    # Get population data for the specific city\n",
    "    census_data = c.acs5.get(\n",
    "        (\n",
    "            \"NAME\",          # City name\n",
    "            \"B01003_001E\",   # Total population\n",
    "        ),\n",
    "        {'for': 'place:*', 'in': f'state:{state_fips}'}\n",
    "    )\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    census_pd = pd.DataFrame(census_data)\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    census_pd = census_pd.rename(\n",
    "        columns = {\n",
    "            \"B01003_001E\": \"Population\",\n",
    "            \"NAME\": \"City\",\n",
    "            \"place\": \"PlaceID\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Find the population for the given city\n",
    "    city_population = census_pd[census_pd['City'].str.strip() == city.strip()]['Population']\n",
    "    \n",
    "    # Return the population if found\n",
    "    if not city_population.empty:\n",
    "        return city_population.iloc[0]\n",
    "    else:\n",
    "        return None  # Return None if the city is not found in the API response\n",
    "\n",
    "# Iterate over rows in df_all_agencies and append the population data\n",
    "population_list = []\n",
    "\n",
    "for index, row in df_all_agencies.iterrows():\n",
    "    city = row['City']\n",
    "    state_abbr = row['State']\n",
    "    \n",
    "    try:\n",
    "        # Fetch the population for the current city\n",
    "        population = get_population_for_city(city, state_abbr)\n",
    "        population_list.append(population)\n",
    "        print(f\"Found Population Data for {city}, {state_abbr} and appended it to population_list.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching population for {city}, {state_abbr}: {e}\")\n",
    "        population_list.append(None)  # Append None if there's an error\n",
    "\n",
    "# Add the population data as a new column in df_all_agencies\n",
    "df_all_agencies['Population'] = population_list\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "print(df_all_agencies.head())\n",
    "\n",
    "# Save the final DataFrame with population data to a new CSV file\n",
    "output_path = \"../Resources/Agency/df_all_agencies_with_population.csv\"\n",
    "df_all_agencies.to_csv(output_path, index=False)\n",
    "print(f\"Data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################  DO NOT RUN THIS CODEEEEEEEEE ##############################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the list of crimes\n",
    "violent_crimes = [\"rape\", \"robbery\", \"aggravated-assault\"]\n",
    "property_crimes = [\"arson\", \"burglary\", \"larceny\", \"motor-vehicle-theft\"]\n",
    "all_crimes = violent_crimes + property_crimes\n",
    "\n",
    "# Define the date range for 2023\n",
    "begin_date = \"01-2023\"\n",
    "end_date = \"12-2023\"\n",
    "time_frame = f\"?from={begin_date}&to={end_date}\"\n",
    "\n",
    "# Function to fetch crime data for a specific agency and crime\n",
    "def fetch_crime_data(ori, crime, time_frame):\n",
    "    # Replace this with your actual API base URL\n",
    "    base_url = f'https://api.usa.gov/crime/fbi/cde/summarized/agency/{ori}/{crime}{time_frame}{api_key}'\n",
    "    response = requests.get(base_url)\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(f\"API call failed for ORI {ori}, crime {crime} with status {response.status_code}\")\n",
    "    return response.json()\n",
    "\n",
    "# Function to process crime data and calculate totals for violent and property crimes\n",
    "def process_crime_data(crime_data, violent_crimes, property_crimes):\n",
    "    violent_total = 0\n",
    "    property_total = 0\n",
    "    population = 0\n",
    "\n",
    "    # Process the data for each crime\n",
    "    for crime, data in crime_data.items():\n",
    "        if crime in violent_crimes:\n",
    "            violent_total += sum(data.get(\"actuals\", {}).values())\n",
    "        elif crime in property_crimes:\n",
    "            property_total += sum(data.get(\"actuals\", {}).values())\n",
    "        # Capture population once (assuming it's consistent across crimes)\n",
    "        if not population:\n",
    "            population = data.get(\"population\", 0)\n",
    "\n",
    "    return violent_total, property_total, population\n",
    "\n",
    "# List to hold the results\n",
    "results = []\n",
    "\n",
    "# Iterate over each agency in the df_all_agencies DataFrame\n",
    "for _, agency in df_all_agencies.iterrows():\n",
    "    ori = agency[\"ORI\"]\n",
    "    state = agency[\"State\"]\n",
    "    agency_name = agency[\"Agency Name\"]\n",
    "    latitude = agency[\"Latitude\"]\n",
    "    longitude = agency[\"Longitude\"]\n",
    "\n",
    "    # Dictionary to hold crime data for the agency\n",
    "    crime_data = {}\n",
    "    \n",
    "    try:\n",
    "        # Fetch data for all crimes\n",
    "        for crime in all_crimes:\n",
    "            crime_data[crime] = fetch_crime_data(ori, crime, time_frame)\n",
    "\n",
    "        # Calculate totals for violent and property crimes\n",
    "        violent_total, property_total, population = process_crime_data(\n",
    "            crime_data, violent_crimes, property_crimes\n",
    "        )\n",
    "\n",
    "        # Append the results\n",
    "        results.append({\n",
    "            \"State\": state,\n",
    "            \"Agency Name\": agency_name,\n",
    "            \"ORI\": ori,\n",
    "            \"Latitude\": latitude,\n",
    "            \"Longitude\": longitude,\n",
    "            \"2023 Violent Crime\": violent_total,\n",
    "            \"2023 Property Crime\": property_total,\n",
    "            \"Population\": population\n",
    "        })\n",
    "\n",
    "        print(f\"Processed data for ORI: {ori} - {agency_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing ORI: {ori} - {agency_name}: {e}\")\n",
    "    \n",
    "    # Pause to avoid overloading the API\n",
    "    # time.sleep(1)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "df_city_crime_data = pd.DataFrame(results)\n",
    "\n",
    "# Calculate rates (instances per 100,000 people)\n",
    "df_city_crime_data[\"Violent Crime Rate\"] = (\n",
    "    df_city_crime_data[\"2023 Violent Crime\"] / df_city_crime_data[\"Population\"] * 100000\n",
    ").round(2)\n",
    "df_city_crime_data[\"Property Crime Rate\"] = (\n",
    "    df_city_crime_data[\"2023 Property Crime\"] / df_city_crime_data[\"Population\"] * 100000\n",
    ").round(2)\n",
    "df_city_crime_data[\"Total Crime Rate\"] = (\n",
    "    (df_city_crime_data[\"2023 Violent Crime\"] + df_city_crime_data[\"2023 Property Crime\"]) / \n",
    "    df_city_crime_data[\"Population\"] * 100000\n",
    ").round(2)\n",
    "\n",
    "# Sort the DataFrame by State and then by Total Crime Rate\n",
    "df_city_crime_data = df_city_crime_data.sort_values(by=[\"State\", \"Total Crime Rate\"])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_path = \"../Resources/Agency/city_crime_data_2023.csv\"\n",
    "df_city_crime_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"City crime data for 2023 saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
